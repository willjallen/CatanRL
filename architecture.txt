
---------------------------------------------------------------------------------
Entity Encoder:
    Inputs: entity_list
    Outputs:
        embedded_entity - A 1D tensor of the embedded entities 
        entity_embeddings - The embedding of each entity (as opposed to `embedded_entity`, which has one embedding for all entities)
The fields of each entity in `entity_list` are first preprocessed and concatenated so that there is a single 1D tensor for each entity. Fields are preprocessed as follows:

unit_type: One-hot with maximum 256 (including unknown unit-type)
unit_attributes: One boolean for each of the 13 unit attributes
alliance: One-hot with maximum 5 (including unknown alliance)
current_health: One-hot of sqrt(min(current_health, 1500)) with maximum sqrt(1500), rounding down
current_shields: One-hot of sqrt(min(current_health, 1000)) with maximum sqrt(1000), rounding down
current_energy: One-hot of sqrt(min(current_health, 200)) with maximum sqrt(200), rounding down
cargo_space_used: One-hot with maximum 9
cargo_space_maximum: One-hot with maximum 9
build_progress: Float of build progress, in [0, 1]
current_health_ratio: Float of health ratio, in [0, 1]
current_shield_ratio: Float of shield ratio, in [0, 1]
current_energy_ratio: Float of energy ratio, in [0, 1]
display_type: One-hot with maximum 5
x_position: Binary encoding of entity x-coordinate, in game units
y_position: Binary encoding of entity y-coordinate, in game units
is_cloaked: One-hot with maximum 5
is_powered: One-hot with maximum 2
is_hallucination: One-hot with maximum 2
is_active: One-hot with maximum 2
is_on_screen: One-hot with maximum 2
is_in_cargo: One-hot with maximum 2
current_minerals: One-hot of (current_minerals / 100) with maximum 19, rounding down
current_vespene: One-hot of (current_vespene / 100) with maximum 26, rounding down
mined_minerals: One-hot of sqrt(min(mined_minerals, 1800)) with maximum sqrt(1800), rounding down
mined_vespene: One-hot of sqrt(min(mined_vespene, 2500)) with maximum sqrt(2500), rounding down
assigned_harvesters: One-hot with maximum 24
ideal_harvesters: One-hot with maximum 17
weapon_cooldown: One-hot with maximum 32 (counted in game steps)
order_queue_length: One-hot with maximum 9
order_1: One-hot across all order IDs
order_2: One-hot across all building training order IDs. Note that this tracks queued building orders, and unit orders will be ignored
order_3: One-hot across all building training order IDs
order_4: One-hot across all building training order IDs
buffs: Boolean for each buff of whether or not it is active. Only the first two buffs are tracked
addon_type: One-hot of every possible add-on type
order_progress_1: Float of order progress, in [0, 1], and one-hot of (`order_progress_1` / 10) with maximum 10
order_progress_2: Float of order progress, in [0, 1], and one-hot of (`order_progress_2` / 10) with maximum 10
weapon_upgrades: One-hot with maximum 4
armor_upgrades: One-hot with maximum 4
shield_upgrades: One-hot with maximum 4
was_selected: One-hot with maximum 2 of whether this unit was selected last action
was_targeted: One-hot with maximum 2 of whether this unit was targeted last action

There are up to 512 of these preprocessed entities, and any entities after 512 are ignored. We use a bias of -1e9 for any of the 512 entries that doesn't refer to an entity.

The preprocessed entities and biases are fed into a transformer with 3 layers of 2-headed self-attention. In each layer, each self-attention head uses keys, queries, and values of size 128, then passes the aggregated values through a Conv1D with kernel size 1 to double the number of channels (to 256). The head results are summed and passed through a 2-layer MLP with hidden size 1024 and output size 256.

The transformer output is passed through a ReLU, 1D convolution with 256 channels and kernel size 1, and another ReLU to yield `entity_embeddings`. The mean of the transformer output across across the units (masked by the missing entries) is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`.

---------------------------------------------------------------------------------